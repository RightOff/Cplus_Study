# 数值比较必要性和可行性

# t 检验概述

t 检验也只能判断两个算法的性能差异是否显著，不能评价它们的具体性能水平。因此，在评估算法性能时，还需要结合具体问题和实际应用场景进行综合考虑。

双样本 t 检验假设两个样本的分布是正态分布，并且假设两个样本的方差相等。如果方差不相等，则可以使用 Welch's t-test 来进行假设检验。如果两个样本均不满足正态性假设，可以使用非参数方法（如 Mann-Whitney U 检验）进行假设检验。

最主要的争议之一是假设检验的结果是否能够支持科学结论以及多重比较问题

## 独立性

![1683170475378](image/假设检验/1683170475378.png)

## 主要流程

要用t检验来比较两个智能优化算法，您需要按照以下步骤进行：

**定义要比较的两个算法** 。假设您的算法是算法A和算法B。

**选择要使用的性能指标** 。例如，您可以选择每个算法在某个数据集上的准确度。

**对于每个算法，运行多次试验，记录每次试验的性能指标值** 。您可以选择运行每个算法的相同次数，并记录每次试验的结果，以确保比较结果的准确性。

**使用****t****检验来比较算法****A****和算法B** **的性能指标** 。t检验可以确定两组数据之间的显著性差异。您可以使用Python中的SciPy库中的ttest_ind()函数来执行t检验。将每个算法的性能指标值作为两组数据输入该函数，并将结果打印出来。

**解释您得到的t** **检验结果** 。如果p值小于0.05，则可以拒绝原假设，即两个算法在所选择的性能指标方面具有显著差异。如果p值大于0.05，则接受原假设，即两个算法在该指标方面没有显著差异。

需要注意的是，t检验只能告诉您两个算法在选择的性能指标方面是否存在显著差异。如果您还想比较其他性能指标或者对算法进行更全面的比较，您可能需要使用其他方法或指标。

# 定义要比较的两个算法

# 性能指标确定

在比较两个智能优化算法的性能时，可以选择一些常用的性能指标，例如：

1. **收敛速度**：表示算法达到收敛状态所需的时间或迭代次数。
2. **收敛精度**：表示算法达到的最优解与真实最优解之间的误差。常用的误差度量包括绝对误差、相对误差和均方根误差等。
3. **稳定性**：表示算法在不同数据集或参数设置下的表现一致性。常用的稳定性指标包括标准差、方差、置信区间等。
4. 搜索空间覆盖率：表示算法能够搜索到的解空间的大小或比例。常用的搜索空间覆盖率指标包括搜索空间大小、搜索空间的采样比例等。
5. 多样性：表示算法在搜索过程中能够维持一定的多样性，避免陷入局部最优解。常用的多样性指标包括种群多样性、个体多样性、解集多样性等。

根据研究问题的具体情况和需求，可以选择不同的性能指标进行比较。在选择指标时，需要确保指标具有客观性、可比性和敏感性，能够充分反映算法的优劣势。同时，指标也需要与算法设计和应用场景相匹配，避免出现不适合实际应用的情况。

用**t检验**本身**只能**用于**比较两个算法在一个指标上的性能差异**是否显著。如果要综合比较两个算法在多个指标上的性能，需要先选定一些代表性能的指标，并**通过一些方法将多个指标综合为一个综合指标**，**然后再用t检验进行比较**。

例如，可以将多个指标通过主成分分析（PCA）等方法进行降维和综合，得到一个代表多个指标的综合指标，然后用t检验比较两个算法在这个综合指标上的性能差异是否显著。但需要注意的是，综合指标的构建需要考虑各个指标的权重和对比算法性能的参考值，否则可能会导致比较结果的偏差。

# 多次试验，记录指标

# 正态性和方差齐性判断

前提条件判断

在使用t检验之前，需要验证数据是否满足一些前提条件，以确保t检验的可靠性。这些**前提条件**包括**正态性**和 **方差齐性** 。如果数据不满足这些前提条件，那么可能需要使用其他方法来比较两个算法的性能。

需要注意的是，如果数据不满足方差齐性的前提条件，也可以使用**非参数检验方法**，例如Wilcoxon秩和检验、Mann-Whitney U检验等，这些方法对数据的分布和方差的假设要求比较宽松。但是需要注意的是， **非参数检验方法可能会牺牲部分精度** ，因此应该根据具体问题来选择合适的方法。**或者进行数据变换** ，使得数据满足前提条件，然后再使用t检验来比较两个算法的性能。

## 正态齐性

**正态性是指数据的分布符合正态分布** 。如果数据符合正态分布，那么t检验的结果**将更可靠**。可以使用一些常用的方法来检验数据是否符合正态分布，例如直方图、正态概率图、偏度峰度检验和Shapiro-Wilk正态性检验等。

Shapiro-Wilk 正态性检验是一种常用的检查数据是否服从正态分布的方法。Shapiro-Wilk 检验会计算一个统计量 W，然后与一个临界值进行比较。如果 W 大于临界值（一般为0.05），那么数据就可以认为服从正态分布。

### Shapiro-Wilk正态性检验

Shapiro-Wilk 正态性检验是一种比较常用的、基于统计学原理的检验方法，它通过计算样本数据与正态分布理论值之间的差距来检验数据是否服从正态分布。Shapiro-Wilk 检验的优点在于它能够检测数据在各个区域的偏差，因此能够更准确地判断数据是否符合正态分布的要求。在实际应用中，建议使用 Shapiro-Wilk 正态性检验来判断数据是否符合正态分布要求。

## 方差齐性

**方差齐性是指不同组别之间的方差应该是相等的** 。如果方差不相等，t检验的结果可能会出现偏差。可以使用**方差齐性检验**来验证数据是否满足方差齐性的前提条件。

方差齐性的基本思想是， **不同组别的样本数据应该具有相同的方差，也就是数据的变异程度应该相同** 。

如果不同组别的方差不相等，那么t检验等方差假设的统计方法可能会出现偏差，导致得出错误的结论。例如， **如果两个组别的方差不同，而我们假设它们相等** ，那么得到的**t** **值可能会偏大或偏小，导致错误地拒绝或接受原假设** 。

为了验证数据是否满足方差齐性的前提条件，可以使用 **方差齐性检验** ，例如**Levene** **检验、** **Bartlett检验**等。这些检验方法会比较不同组别之间的方差是否相等，并给出相应的显著性水平。如果p值小于显著性水平，说明不同组别之间的方差不相等，需要使用修正后的统计方法或者进行数据变换。

### Levebe检验

假设我们有两个智能优化算法 A 和 B，它们的目标是在某个优化问题上获得最佳解，我们对它们进行了若干次独立的实验，得到了两个算法在该问题上的指标数据，我们希望通过 Levene 检验来判断这些数据是否满足方差齐性的前提条件。

假设我们对两个算法分别进行了 10 次实验，得到的数据如下：

```
Algorithm A: [2.5, 3.0, 2.8, 2.9, 3.1, 3.3, 3.2, 2.7, 2.6, 2.9]
Algorithm B: [3.1, 3.3, 3.0, 3.2, 2.8, 3.1, 2.9, 3.0, 2.7, 2.8]
```

我们可以使用 Python 的 Scipy 库来进行 Levene 检验。具体步骤如下：

```
from scipy.stats import levene

# 进行 Levene 检验
statistic, pvalue = levene(A, B)

# 输出结果
print(f"Levene statistic: {statistic}")
print(f"p-value: {pvalue}")
```

输出结果为：

```
Levene statistic: 0.01070499999999981
p-value: 0.9178564653837492
```

从输出结果可以看出，Levene 检验的 p 值为 0.918，大于显著性水平 0.05，说明两个算法的指标数据满足方差齐性的前提条件。

需要注意的是，**Levene 检验的结果也受到样本量的影响**，当样本量较小时，检验结果可能不够准确，因此应该根据具体情况来决定样本量的大小。

正态性和方差齐性判断代码如下

```
# 正态性和方差齐性判断
def Shapiro_Wilk_and_Levene(arr1, arr2):
    # 进行Shapiro-Wilk正态性检验
statA, pA = shapiro(arr1)
    statB, pB = shapiro(arr2)
    # 进行levene方差齐性检验
stat, p = levene(dataA, dataB)

    if pA > 0.05 and pB > 0.05 and p > 0.05:
        # 两组数据符合正态分布和方差齐性的假设
print("两组数据都符合正态分布和方差齐性的假设")
        return 1
elif pA < 0.05 and pB < 0.05 and p < 0.05:
        print("两组数据都不符合正态分布和方差齐性的假设")
    elif pA < 0.05:
        print("A组数据不符合正态分布的假设")
    elif pB < 0.05:
        print("B组数据不符合正态分布的假设")
    elif pA < 0.05:
        print("两组数据不符合方差齐性的假设")
    return -1
```

## 数据变换

### 正态分布

常见的数据变换方法：

1. 对数变换：对于右偏分布的数据，可以使用自然对数、十进制对数或其他对数进行变换。
2. 平方根变换：可以将数据开平方根来缩小数据的范围。
3. 倒数变换：可以将数据取倒数来缩小数据的范围。
4. Box-Cox 变换：对于非正的数据，可以使用 Box-Cox 变换来进行转换。 Box-Cox 变换是一种参数化函数变换，可以将数据变换为服从正态分布的数据。

在进行数据变换时，需要注意以下几点：

1. 数据变换应该基于实际问题和数据分布的特点，不应该盲目地进行。
2. 数据变换可能会改变数据的单位和解释，因此需要谨慎选择变换方法。
3. 数据变换后，需要进行正态性检验来确保数据符合正态分布假设。可以使用 Shapiro-Wilk 检验、Kolmogorov-Smirnov 检验或其他正态性检验方法。

变换之后如果数据的方差不相等，可以使用 Welch's t-test 来代替经典的 t 检验。

另外，需要注意的是，在进行t检验时， **应该确保样本数据来自于独立的随机抽样** ，并且 **样本数据的大小应该足够大** ，以保证统计结果的可靠性。

# 开始t检验

## 设置原假设和备择假设

在假设检验中， **原假设通常是指我们希望证伪或者拒绝的假设** 。对于比较两个算法的性能来说， **原假设可以是两个算法的性能没有显著差异，也可以是两个算法的性能有显著差异** 。在实际应用中，选择哪个假设作为原假设，取决于研究者所关心的问题以及研究的目的。

如果研究者 **关心的是两个算法的性能是否有显著差异** ，那么 **原假设可以是两个算法的性能没有显著差异** 。在这种情况下，研究者需要通过假设检验来判断两个算法的性能是否有显著差异。

如果研究者关心的是 **两个算法中哪一个更好** ，那么 **原假设可以是其中一个算法比另一个算法更好，或者是两个算法的性能相等** 。在这种情况下，研究者需要通过假设检验来判断哪个算法更好，或者是两个算法的性能是否相等。

需要注意的是，在进行假设检验时，**原假设和备择假设应该是互为补集**的。例如，如果原假设是两个算法的性能没有显著差异，那么备择假设就应该是两个算法的性能有显著差异。这样做可以保证假设检验的结果是明确的，有意义的。

## 调用算法包进行检验

如果**p** **值大于显著性水平，那么就不能拒绝原假设** ，即不能认为两个算法的性能有显著差异。一般来说，显著性水平常用的取值为0.05或0.01，这意味着如果p值大于0.05（或0.01），就不能拒绝原假设。如果p值小于0.05（或0.01），则可以拒绝原假设，认为两个算法的性能有显著差异。

p值其含义是样本间的差异由抽样误差所致的概率小于0.05 、0.01、0.001

需要注意的是， **即使不能拒绝原假设，也不代表两个算法的性能完全相同** ， **只是说我们没有足够的证据去证明它之间存在显著的差异** 。此时可能需要对数据进行更加深入的分析，例如通过可视化方法来观察两个算法在不同数据集上的表现，或者通过其他统计方法来检验两个算法性能的差异。

需要注意的是， **显著性水平的选择应该根据具体问题来确定** ，不能一概而论。 **显著性水平越小，代表拒绝原假设的要求越高** ， **即认为两个算法的性能差异更显著** ，但也会 **增加犯第一类错误（即错误地拒绝了原假设）的风险** 。

### t值正负的含义

t值的正负表明了两个样本均值之间的差异方向，即样本均值差异的正负方向。当t值为正数时，表示样本均值差异为正，即样本A的均值大于样本B的均值；当t值为负数时，表示样本均值差异为负，即样本A的均值小于样本B的均值。

# 举例：

假设我们要比较两个遗传算法（算法A和算法B）在求解二元函数（$f(x, y) = x^2 + y^2$）的最小值时的性能。我们将使用t检验来比较这两个算法的性能。

具体步骤如下：

## 定义要比较的两个算法

遗传算法A和遗传算法B。

## 选择要使用的性能指标

这里我们选择每个算法在求解$f(x,y)=x^2+y^2$最小值时需要的迭代次数。

## 对于每个算法，运行多次试验，记录每次试验的性能指标值

我们将每个算法在同样的初始参数下分别运行10次试验，并记录每次试验的迭代次数，得到如下的数据：

| Algorithm | Iteration times (10 experiments)                 |
| --------- | ------------------------------------------------ |
| A         | 120, 135, 126, 132, 128, 124, 131, 129, 127, 123 |
| B         | 140, 145, 136, 142, 138, 134, 141, 139, 137, 133 |

## 正态性和方差齐性判断

```
# 正态性和方差齐性判断
Shapiro_Wilk_and_Levene=Shapiro_Wilk_and_Levene(dataA, dataB)
```

## t检验

### 设置原假设和备择假设

原假设：两种算法的性能相等	备择假设：两种算法的性能不相等

### 运行t检验

我们使用Python中的SciPy库来运行t检验。具体代码如下：

```
 # 两组数据都符合正态分布和方差齐性的假设，则运行t检验
 t_statistic, p_value = ttest_ind(alg_a, alg_b)

 # 打印结果
 print("t-statistic:", t_statistic)
 print("p-value:", p_value)
```

运行以上代码，得到的输出结果如下：

```
t-statistic: -5.975359238806223
p-value: 1.1853770353958373e-05
```

**解释**t****检验结果：我们得到的p-value**值(1.1853770353958373e-05)小于** **0.05**，说明在所选择的性能指标（迭代次数）上，算法A和算法B的性能有显著差异。因此，我们可以认为算法****B**在求解**  **$f(x,y)=x^2+y^2$** **最小值时比算法****A****更好。**

需要注意的是，以上例子仅仅是对两个算法在一个特定的问题上进行了简单的比较，如果要比较更多算法在多个问题上的性能，可能需要更复杂的实验设计和统计分析方法。

如果**p****值小于显著性水平，且****t** **值为正** ，说明算法B的平均迭代次数要比算法A的平均迭代次数少，且这个差异相对于两个算法的标准误差来说是显著的。反之，**如果****p****值小于显著性水平，且t** **值为负** ，说明算法B的平均迭代次数要比算法A的平均迭代次数多，且这个差异也是显著的。

两个算法涉及多个指标如何使用t检判断他们是否有显著差异性
